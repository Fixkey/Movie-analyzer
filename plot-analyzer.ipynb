{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "try:\n",
    "    stopwords.words('english')\n",
    "except LookupError:\n",
    "    nltk.download('stopwords')\n",
    "\n",
    "def remove_stops(text, stops):\n",
    "    text = text.lower().translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    \n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in stops]\n",
    "    \n",
    "    final_text = \" \".join(filtered_words)\n",
    "    \n",
    "    final_text = ''.join([i for i in final_text if not i.isdigit()])\n",
    "    \n",
    "    return final_text\n",
    "\n",
    "def clean_plots(docs):\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    final_docs = [remove_stops(doc, stops) for doc in docs]\n",
    "    \n",
    "    return final_docs\n",
    "\n",
    "plots_json = pd.read_json(\"./results/plots.json\")\n",
    "plots = plots_json['plot']\n",
    "cleaned_plots = clean_plots(plots)\n",
    "ids = plots_json['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "                                lowercase=True,\n",
    "                                max_features=100,\n",
    "                                max_df=0.8,\n",
    "                                min_df=5,\n",
    "                                ngram_range = (1,3),\n",
    "                                stop_words = \"english\"\n",
    "                            )\n",
    "\n",
    "vectors = vectorizer.fit_transform(cleaned_plots)\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "dense = vectors.todense()\n",
    "denselist = dense.tolist()\n",
    "\n",
    "all_keywords = []\n",
    "\n",
    "for description in denselist:\n",
    "    x=0\n",
    "    keywords = []\n",
    "    for word in description:\n",
    "        if word > 0:\n",
    "            keywords.append(feature_names[x])\n",
    "        x=x+1\n",
    "    all_keywords.append(keywords)\n",
    "\n",
    "true_k = 12\n",
    "\n",
    "model = KMeans(n_clusters=true_k, init=\"k-means++\", max_iter=100, n_init=1)\n",
    "\n",
    "model.fit(vectors)\n",
    "\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names_out()\n",
    "\n",
    "cluster_labels = model.labels_\n",
    "\n",
    "id_to_cluster = pd.DataFrame({'id': ids, 'cluster': cluster_labels})\n",
    "id_to_cluster.to_csv('results/id_to_cluster.csv', index=False)\n",
    "\n",
    "cluster_terms = pd.DataFrame(columns=['Id','Name', 'Top Terms'])\n",
    "\n",
    "rows = []\n",
    "for i in range(true_k):\n",
    "    top_terms = ', '.join([terms[ind] for ind in order_centroids[i, :10]])\n",
    "    rows.append({'Id': i, 'Name': f'Cluster {i}', 'Top Terms': top_terms})\n",
    "\n",
    "cluster_terms = pd.concat([cluster_terms, pd.DataFrame(rows)], ignore_index=True)\n",
    "cluster_terms.to_csv('results/cluster_terms.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['agent', 'american', 'army', 'attempt', 'battle', 'begins', 'best',\n",
       "       'bond', 'boy', 'called', 'child', 'city', 'crew', 'crime',\n",
       "       'dangerous', 'daughter', 'day', 'death', 'detective', 'discover',\n",
       "       'discovers', 'earth', 'evil', 'falls', 'family', 'father', 'fight',\n",
       "       'finds', 'forced', 'forces', 'friend', 'friends', 'future', 'game',\n",
       "       'girl', 'goes', 'group', 'help', 'high', 'high school', 'home',\n",
       "       'human', 'james', 'john', 'killer', 'learns', 'life', 'lives',\n",
       "       'love', 'make', 'makes', 'man', 'meets', 'mother', 'murder',\n",
       "       'mysterious', 'new', 'new york', 'new york city', 'old', 'order',\n",
       "       'past', 'people', 'plan', 'planet', 'police', 'powerful', 'real',\n",
       "       'relationship', 'rescue', 'return', 'save', 'school', 'secret',\n",
       "       'sent', 'sets', 'small', 'son', 'star', 'stop', 'story', 'takes',\n",
       "       'team', 'teenager', 'time', 'town', 'train', 'tries', 'true',\n",
       "       'trying', 'war', 'way', 'wife', 'woman', 'work', 'world', 'years',\n",
       "       'york', 'york city', 'young'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
